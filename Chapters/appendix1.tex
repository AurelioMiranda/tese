%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% appendix1.tex
%% NOVA thesis document file
%%
%% Chapter with example of appendix with a short dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE appendix1.tex}%

\chapter{Appendix}
\label{app:intro}



\section{Comment Configuration}
\label{app:comment}


\subsection{Comment Configuration Example 1}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{nocomment_example1.png}
	\caption{Example of generated code without comments}
	\label{figapp:nocomment_example1}
\end{figure}

When code comments are toggled on, the code from Figure~\ref{figapp:nocomment_example1} becomes the code from Figure~\ref{figapp:comment_example1}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{comment_example1.png}
	\caption{Example of generated code with comments}
	\label{figapp:comment_example1}
\end{figure}

Figure~\ref{figapp:comment_example1} has detailed comments about each component, highlighting and explaining specific code sections.


\newpage

\section{Integration and Regression Tests}
\label{app:int_and_reg_tests}


\bgroup
\rowcolors{1}{}{GhostWhite}
\begin{xltabular}{\textwidth}{X X X}
	\caption{Feature dependency table}
	\label{tab:app_int_and_reg_tests}\\
	\toprule
	\rowcolor{Gainsboro}%
	Feature & Depends On & Notes \\
	\midrule
	\Glspl{identifier} & - & Core to code structure \\
	Comments & \Glspl{identifier} & Cheap to implement early \\
	Traceability & \Glspl{identifier}, Comments & Hard to retrofit later \\
	Report & Traceability & Uses trace data \\
	Standard\par Compliance & Report, Traceability & Enforce compliance early \\
	Dead Code\par Elimination & Traceability, Report & Needs stable generation logic \\
	Memory\par Optimization & Dead Code Elim, Traceability & Impacts data structures directly \\
	Node Interface & Memory Optimization & Enables \gls{ROS} decoupling \\
	Legacy Code\par Integration & Node Interface & Most architecture-dependent \\
	\bottomrule
\end{xltabular}


\section{Workflow Execution Time Runs}
\label{app:workflow_exec_time}


\bgroup
\rowcolors{1}{}{GhostWhite}
\begin{xltabular}{\textwidth}{X X X X X X X X X X}
	\caption{First run of workflow execution times (in ms) for an average model with the set of configs from~\ref{app:config_first_batch}}
	\label{tab:workflow_exec_times_1}\\
	\toprule
	\rowcolor{Gainsboro}
Run & Code & Launch & CMake & Package & Trace & Report & Total Steps & Total & Project Time \\
\midrule
1  & 194 & 65 & 54 & 35 & 92 & 208 & 648 & 663 & 348 \\
2  & 183 & 88 & 58 & 30 & 85 & 205 & 649 & 674 & 359 \\
3  & 138 & 64 & 49 & 34 & 81 & 185 & 551 & 568 & 285 \\
4  & 119 & 50 & 38 & 26 & 74 & 159 & 466 & 477 & 233 \\
5  & 113 & 51 & 43 & 36 & 76 & 163 & 482 & 495 & 243 \\
6  & 104 & 67 & 38 & 27 & 66 & 178 & 480 & 491 & 236 \\
7  & 103 & 43 & 34 & 24 & 66 & 147 & 417 & 425 & 204 \\
8  & 96  & 45 & 38 & 26 & 77 & 142 & 424 & 438 & 205 \\
9  & 89  & 40 & 34 & 24 & 71 & 145 & 403 & 414 & 187 \\
10 & 89  & 45 & 35 & 24 & 70 & 154 & 417 & 426 & 193 \\
11 & 93  & 42 & 34 & 22 & 65 & 162 & 418 & 425 & 191 \\
12 & 86  & 60 & 35 & 25 & 68 & 151 & 425 & 437 & 206 \\
13 & 94  & 52 & 37 & 27 & 67 & 153 & 430 & 438 & 210 \\
14 & 89  & 41 & 34 & 23 & 62 & 155 & 404 & 413 & 187 \\
15 & 87  & 42 & 34 & 24 & 65 & 153 & 405 & 415 & 187 \\
\bottomrule
\end{xltabular}

When observing Table~\ref{tab:workflow_exec_times_1} we can see that the Trace and Report generation take a more significant amount of time due to their additional checks (line traces and code quality checks respectively).

The downward trend in the first few runs can be attributed to common warmup effects present in development environments. These may include plug-in in initialization, caching and class loading. After these initializations, subsequent runs exhibit more stable and normalized execution times.


\section{Generator Configuration Options}
\label{app:configs}


\subsection*{Complete Project Configuration}
\label{app:config_first_batch}

\begin{description}
	\item[Naming]
	\begin{description}
		\item[Style:] \texttt{STANDARD}
		\item[Affix:] \texttt{Telecom\_}
		\item[Affix position:] \texttt{PREFIX}
	\end{description}
	
	\item[Report]
	\begin{description}
		\item[Generate:] \texttt{true}
		\item[Include traceability:] \texttt{true}
		\item[Include summary tables:] \texttt{true}
		\item[Include ROS summaries:] \texttt{true}
		\item[Show detected errors:] \texttt{true}
	\end{description}
	
	\item[Decoupling] Enabled
	
	\item[Comments] \texttt{true}
	
	\item[Traceability] \texttt{true}
\end{description}


\subsection{Configuration UML}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{configLanguageUML.png}
	\caption{UML Diagram of the configuration language, made by the author}
	\label{figapp:configLanguageUML}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{configLanguageUMLRotated.png}
\caption{UML Diagram of the configuration language rotated 90 degrees for better view}
\label{figapp:configLanguageUMLRotated}
\end{figure}


\newpage

\section{Tests}
\label{app:unit_tests}


\bgroup
\rowcolors{1}{}{GhostWhite}
\begin{xltabular}{\textwidth}{X X X}
	\caption{Code generation verification tests}
	\label{tab:codegen_tests}\\
	\toprule
	\rowcolor{Gainsboro}%
	Test Case ID & Feature & Description \\
	\midrule
	TC-CG-01 & ROS Package Structure & Verify presence of expected folders (\texttt{src}, \texttt{src/launch}) and required files (\texttt{CMakeLists.txt}, \texttt{package.xml}, \texttt{launch.xml}). \\
	TC-CG-02 & Source Code Equivalence & Compare generated \texttt{src} folder with control reference. \\
	TC-CG-03 & Launch File Equivalence & Compare generated \texttt{launch.xml} with control reference at node/remap level. \\
	TC-CG-04 & CMake Consistency & Compare generated \texttt{CMakeLists.txt} with expected reference. \\
	TC-CG-05 & Package Metadata & Compare generated \texttt{package.xml} with expected reference. \\
	TC-CG-06 & Trace Output & Verify \texttt{trace.json} against control reference. \\
	TC-CG-07 & HTML Report & Compare generated report (\texttt{report.html}) with expected. \\
	TC-CG-08 & Static Analysis Report & Compare generated \texttt{cppcheck-report.xml} with control reference. \\
	TC-CG-09 & Node-CMake Consistency & Ensure executables referenced in \texttt{launch.xml} are defined as targets in \texttt{CMakeLists.txt} (with optional \_Node suffix).  \\
	TC-CG-10 & Colcon Build (Disabled) & Attempt build of generated workspace using \texttt{colcon}. Currently disabled due to environment constraints. \\
	\bottomrule
\end{xltabular}
\egroup

The tests observed in Table~\ref{tab:codegen_tests} were implemented as unit tests. Being extremely useful at keeping feature and runtime consistency during development.


\subsection{Unit test execution times}
\label{app:unit_test_times}

\begingroup
\rowcolors{1}{}{GhostWhite}
\begin{xltabular}{\textwidth}{X X X X}
	\caption{Test execution times for standalone and plugin tests}
	\label{tab:test_times}\\
	\toprule
	\rowcolor{Gainsboro}%
	Test Group & Run & Standalone Time (s) & Plugin Time (s) \\
	\midrule
	1 test & 1 & 7.16 & 16.81 \\
	& 2 & 5.58 & 17.90 \\
	& 3 & 5.42 & 18.06 \\
	& 4 & 5.55 & 16.30 \\
	& 5 & 5.42 & 16.32 \\
	\midrule
	10 tests & 1 & 18.59 & 28.07 \\
	& 2 & 18.73 & 28.50 \\
	& 3 & 18.45 & 28.95 \\
	& 4 & 18.60 & 28.20 \\
	& 5 & 18.55 & 28.10 \\
	\midrule
	20 tests & 1 & 27.84 & 35.97 \\
	& 2 & 28.01 & 36.31 \\
	& 3 & 27.90 & 36.05 \\
	& 4 & 27.95 & 36.10 \\
	& 5 & 28.05 & 36.06 \\
	\midrule
	50 tests & 1 & 34.29 & 41.45 \\
	& 2 & 34.27 & 41.76 \\
	& 3 & 34.35 & 41.50 \\
	& 4 & 34.32 & 41.60 \\
	& 5 & 34.30 & 41.55 \\
	\midrule
	>100 tests & 1 & 63.69 & 71.45 \\
	& 2 & 64.91 & 73.62 \\
	& 3 & 64.87 & 73.26 \\
	& 4 & 64.50 & 72.80 \\
	& 5 & 64.75 & 73.10 \\
	\bottomrule
\end{xltabular}
\endgroup

Table~\ref{tab:test_times} highlights how the plug-in and standalone testing environments compare in terms of execution time. The derived conclusion is that standalone testing reduces execution time by a mostly fixed amount (which correlated to the plug-in environment start up). Being beneficial, especially with lower test amounts.

\subsection{System Usability Scale}
\label{app:sus}

The following questions were used in the \gls{SUS} questionnaire.

\begin{enumerate}
	\item I would enjoy using this system frequently.
	\item I found the system unnecessarily complex.
	\item I thought the system was easy to use.
	\item I think that I would need technical support to use this system.
	\item I found the various functions in the system were well integrated.
	\item I thought there was too much inconsistency in the system.
	\item I imagine most people would learn to use this system very quickly.
	\item I found the system very cumbersome to use (feels heavy, awkward, slow, or overly complicated).
	\item I felt very confident using the system.
	\item I needed to learn a lot of things before I could get going with this system.
\end{enumerate}

Responses are recorded on a 5-point Likert scale:
1 = Strongly Disagree, 5 = Strongly Agree.

\subsubsection{\gls{SUS} scores}
\label{app:sus_scores}

\begin{table}[htbp]
	\centering
	\caption{\gls{SUS} Scores per Participant}
	\label{tab:sus_scores_appendix}
	\begin{tabular}{l c c c c c c c c c c}
		\toprule
		Participant & Q1 & Q2 & Q3 & Q4 & Q5 & Q6 & Q7 & Q8 & Q9 & Q10 \\
		\midrule
		P1 & 4 & 2 & 4 & 2 & 3 & 2 & 5 & 1 & 4 & 3 \\
		P2 & 5 & 3 & 4 & 2 & 4 & 2 & 3 & 3 & 4 & 3 \\
		P3 & 4 & 2 & 4 & 2 & 4 & 2 & 5 & 1 & 4 & 2 \\
		P4 & 4 & 2 & 4 & 1 & 4 & 1 & 5 & 2 & 4 & 1 \\
		P5 & 4 & 2 & 4 & 3 & 5 & 2 & 5 & 1 & 4 & 4 \\
		\bottomrule
	\end{tabular}
\end{table}

Table~\ref{app:sus_scores} illustrates the scores by the participants in the \gls{SUS} questionnaire.

\subsection{Task Booklet}
\label{app:task_book}

The following task booklet was handed (on paper) to the participants in order to test the developed \gls{DSL}:


\begin{verbatim}
Usability Study Task Booklet
RAMSES Configuration Language
Follow the tasks in order. Don’t forget to Apply the settings.
If you believe a task is complete, tell the evaluator before moving on.

Section A – Basic Configuration
	1.	Select C++ as the target language.
	2.	Select Linux as the target operating system.
	3.	Set the output directory for generated code.
	4.	Generate the code.
	
Section B – Naming and Identifier Settings
	1.	Change the identifier naming style to snake\_case.
	2.	Apply a prefix of your choice to all identifiers.
	
Section C – Traceability and Report
	1.	Enable documentation comments and set yourself as the author.
	2.	Enable report generation.
	3.	Enable logic summaries in the report.
	4.	Enable traceability.
	5.	Enable the generation of a traceability JSON.
	
Section D – Advanced Configuration
	1.	Enable business logic decoupling.
	2.	Change executor type to multi-thread).
	3.	Configure legacy libraries with copy to project.
	4.	Add a pre and post generation script.

Section E – Build and Output
	1.	Set the file prefix option as your name.
	2.	Enable file overwriting.
	3.	Disable launch file generation.

Section F – Full Workflow Validation
	1.	Trigger code generation with the current settings.
	2.	Verify that the generated files match the chosen configuration:
		o	identifier casing
		o	comments
		o	report presence
		o	traceability JSON
		o	build artifacts
	
End of Task Booklet
Please notify the evaluator that you have finished.
Then proceed to the SUS and NASA-TLX questionnaires.
\end{verbatim}

\subsubsection{Time taken per task}
\label{app:ttpt}

Table~\ref{tab:ttpt} describes the time taken by each participant on each task.

\begin{table}[htbp]
	\centering
	\caption{Usability Task Performance Summary}
	\label{tab:ttpt}
	\begin{tabular}{lccccc}
		\toprule
		\textbf{Task} & Participant 1 & Participant 2 & Participant 3 & Participant 4 & Participant 5 \\
		\midrule
		Select target language &  &  &  &  & \\
		Configure naming style &  &  &  &  &  \\
		Apply identifier prefix/suffix &   &  &  &  &  \\
		Enable/disable comments &  &  &  &  &  \\
		Enable/disable report generation &  &  &  &  &  \\
		Enable/disable traceability &  &  &  &  &  \\
		Toggle business logic decoupling &  &  &  &  &  \\
		Change executor type &  &  &  &  &  \\
		Configure legacy libraries &  &  &  &  &  \\
		Enable file overwriting &  &  &  &  &  \\
		Set file prefix &  &  &  &  &  \\
		Manage build file generation &  &  &  &  & \\
		Add pre/post scripts &  &  &  &  & \\
		Trigger code generation &  &  &  &  &  \\
		Verify outputs &  &  &  &  &  \\
		\midrule
		\textbf{Totals} &  &  &  &  &  \\
		\bottomrule
	\end{tabular}
\end{table}


\subsection{Moderator Script}
\label{app:mod_script}

The following script was read to participants before the start of each usability test:

\begin{verbatim}
Participant Instruction Sheet

Usability Study – RAMSES Configuration Language

Purpose of the Study
You will be evaluating a configuration interface used to customize code 
generation in the RAMSES toolchain. The goal is to understand how intuitive 
and understandable the configuration language and user interface are for AADL users.

This is not a test of your skills.
We are evaluating the tool, not the participant.

Your Task

You will complete a series of configuration tasks inside an Eclipse-based 
environment. These tasks involve adjusting settings such as identifier naming, 
comments, report generation, traceability, and other code-generation options.

You will receive:
A short task booklet
Access to the configuration interface
No guidance unless explicitly requested
What Will Be Recorded

During the session, the evaluator will record:
How long each task takes
Errors or missteps
Help requests
Any visible signs of confusion or hesitation
Optional verbal feedback

After completing the tasks, you will fill out:
The System Usability Scale (SUS)
The NASA Task Load Index (NASA-TLX)

These questionnaires measure perceived usability and mental workload.

Ground Rules
You may ask questions only if something is unclear.
You may stop at any time.
There are no right or wrong answers.
Work at your natural pace.
We value your honest feedback.

Confidentiality

Your identity will not be recorded in the study.
You will be referenced only as Participant P1–P5.
No personal information will appear in the thesis.
\end{verbatim}





