%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter6.tex
%% NOVA thesis document file
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter6.tex}%

\chapter{Software Testing}
\label{cha:test}


\epigraph{ \textit{This chapter documents the software testing done throughout the development of the thesis. It highlights how the specific tests where done, in what context and their results.}}


Intro intro intro?


\section{Feature Testing}
\label{sec:test_feature}

This type of testing is recurrent along the development, it serves to ensure that the features implemented are functioning as intended and that the previous version of the software has retained its functionality when new features were added.

\section{Feature Testing}
\label{sec:test_feature_one}

After the development of the first batch of features, the testing served to ensure that the previous version of the code generator was still working as intended and to validate the integration of the code generator configurator in the pipeline.

The report for the first volley of tests can be found in the Annex~\ref{label}, where it is explained the purpose of each individual test and the results they withheld.

The regression tests applied at this time were limited since the previous version of the software did not include any code generation customization, only the simple transition from model to code (\gls{M2T}), which, after generating a \gls{ROS} project in both the previous code generator and the at the time current one (with the first batch of features implemented), it was possible to verify that both generators still produced the same practical output, essentially, the code produced by both generators yields the same functionality.

The integration test part was done much more in depth since the goal was to intertwine the different new features and find out if they worked in perfect harmony as expected. The following tests were conducted:

\begin{itemize}
	\item \textbf{TC-INT-01 – Identifier Consistency:} Verify that the identifier configuration set in the \texttt{config.generator} model is applied consistently in generated C++ code and reflected in the traceability file as well as in the report.
	
	\item \textbf{TC-INT-02 – Comment Preservation Across Modules:} Generate code from a model containing both single-line and multi-line comments, verifying that:
	\begin{enumerate}
		\item Acceleo templates correctly output the comments.
		\item Java generator preserves formatting.
	\end{enumerate}
	
	\item \textbf{TC-INT-03 – Traceability Link Accuracy:} Confirm that model elements are mapped to the correct files and line numbers in generated code, and that these mappings are:
	\begin{enumerate}
		\item Present in the \gls{JSON} traceability output.
		\item Referenced in the \gls{HTML} report.
	\end{enumerate}
	
	\item \textbf{TC-INT-04 – Report Generation Data Flow:} Metrics collected during generation (number of components, code quality warnings) are passed from the Java generator to the report module and rendered correctly in the final report.
	
	\item \textbf{TC-INT-05 – Code Quality \& Report Synchronization:} Trigger a known style violation in the model, generate code, and verify that:
	\begin{enumerate}
		\item The code quality checker detects it and outputs XML.
		\item The Java generator correctly embeds this warning into the final HTML reportx.
	\end{enumerate}
	
	\item \textbf{TC-INT-07 – Cross-Feature Stability:} Use a large, complex model with:
	\begin{itemize}
		\item Custom identifiers
		\item Extensive comments
		\item Nested subcomponents
		\item Known style violations
	\end{itemize}
	Verify that all features (identifier config, comments, traceability, reporting, quality checking) work together without breaking any module.
\end{itemize}





